{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- No missing values (good)\n",
    "- There are features with slight colleration w.r.t. the Attrition (they are also explainable)\n",
    "- There are three features immediately to be dropped because of 1 distinct value\n",
    "- We are left with 19 categorical and 13 numerical features\n",
    "- ID type of feature is also excluded (numerical features down to 12)\n",
    "- Number of numerical features gone up to 23, nominals down to 7, because of instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.tree import ExtraTreeClassifier as ETC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression as LRC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "from utils.evaluation import *\n",
    "from utils.dataprep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \n",
      "Accuracy score: 81.36054421768706 +/- 4.239574544457928\n",
      "Recall score: 5.579710144927537 +/- 11.50663260875477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gergo\\anaconda3\\envs\\sq\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gergo\\anaconda3\\envs\\sq\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gergo\\anaconda3\\envs\\sq\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gergo\\anaconda3\\envs\\sq\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gergo\\anaconda3\\envs\\sq\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gergo\\anaconda3\\envs\\sq\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 8.710907704042716 +/- 11.492060309459307\n",
      "F1 score: 12.819837160810794 +/- 14.146490752790836\n",
      "Model with PCA:\n",
      "Accuracy score: 82.5170068027211 +/- 2.2572326561955203\n",
      "Recall score: 28.786231884057965 +/- 37.12905962137999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gergo\\anaconda3\\envs\\sq\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Gergo\\anaconda3\\envs\\sq\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 23.890380410595768 +/- 29.7974978703201\n",
      "F1 score: 12.007619414377864 +/- 12.44538271031943\n",
      "Model with PCA and undersampling:\n",
      "Accuracy score: 55.646258503401356 +/- 10.955549463508788\n",
      "Recall score: 70.5072463768116 +/- 19.974877889285615\n",
      "Precision score: 19.09639072752651 +/- 2.7804454584221947\n",
      "F1 score: 26.952979600654718 +/- 3.7177934114955997\n",
      "Model with PCA and scaling:\n",
      "Accuracy score: 85.03401360544217 +/- 2.2766259225417\n",
      "Recall score: 43.09782608695652 +/- 8.631043949588909\n",
      "Precision score: 56.715436696086854 +/- 12.61326702411128\n",
      "F1 score: 50.72651658152402 +/- 8.959586290048344\n",
      "Model with PCA, scaling and undersampling:\n",
      "Accuracy score: 73.33333333333334 +/- 3.999166926992944\n",
      "Recall score: 65.018115942029 +/- 11.794146110790374\n",
      "Precision score: 33.040805759061 +/- 4.142390485125199\n",
      "F1 score: 43.50106064575519 +/- 5.1291379430814565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 73.33333333333334,\n",
       "  'recall': 65.018115942029,\n",
       "  'precision': 33.040805759061,\n",
       "  'f1': 43.50106064575519},\n",
       " {'accuracy': 3.999166926992944,\n",
       "  'recall': 11.794146110790374,\n",
       "  'precision': 4.142390485125199,\n",
       "  'f1': 5.1291379430814565})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/use_case_employee-attrition.csv\")\n",
    "df = df.drop([\"EmployeeCount\", \"Over18\", \"StandardHours\", \"EmployeeNumber\"], axis=1)\n",
    "\n",
    "nominals = [\"BusinessTravel\", \"Department\", \"EducationField\", \"Gender\", \"JobRole\", \"MaritalStatus\", \"OverTime\"]\n",
    "numericals = [\"Age\", \"DailyRate\", \"DistanceFromHome\", \"Education\", \"EnvironmentSatisfaction\", \"HourlyRate\", \"JobInvolvement\", \"JobLevel\", \"JobSatisfaction\", \"MonthlyIncome\", \"MonthlyRate\", \"NumCompaniesWorked\",\n",
    "              \"PercentSalaryHike\", \"PerformanceRating\", \"RelationshipSatisfaction\", \"StockOptionLevel\", \"TotalWorkingYears\", \"TrainingTimesLastYear\", \"WorkLifeBalance\", \"YearsAtCompany\", \"YearsInCurrentRole\", \n",
    "              \"YearsSinceLastPromotion\", \"YearsWithCurrManager\"]\n",
    "\n",
    "df_t = onehot_columns(df, nominals)\n",
    "df_n = merge_onehotted(df, df_t, nominals)\n",
    "\n",
    "X = df_n.drop(\"Attrition\", axis=1)\n",
    "y = df_n[\"Attrition\"]\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "pca = PCA(n_components=15)\n",
    "resampler = RandomUnderSampler(random_state=42)\n",
    "model = MLP(hidden_layer_sizes=(100, 10), max_iter=5000)\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"pca\", pca, df_t.columns),\n",
    "        (\"passthrough\", \"passthrough\", numericals)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"column_transformer\", column_transformer), (\"classifier\", model)])\n",
    "pipeline_s = Pipeline(steps=[(\"column_transformer\", column_transformer), (\"scaler\", scaler), (\"classifier\", model)])\n",
    "\n",
    "steps = [\n",
    "    (\"undersample\", resampler),\n",
    "    (\"pca\", pca),\n",
    "    (\"classifier\", model)\n",
    "]\n",
    "\n",
    "ipipeline = ImbPipeline(steps=steps)\n",
    "\n",
    "steps = [\n",
    "    (\"undersample\", resampler),\n",
    "    (\"scaler\", scaler),\n",
    "    (\"pca\", pca),\n",
    "    (\"classifier\", model)\n",
    "]\n",
    "\n",
    "ipipeline_s = ImbPipeline(steps=steps)\n",
    "\n",
    "steps = [\n",
    "    (\"undersample\", resampler),\n",
    "    (\"scaler\", scaler),\n",
    "    (\"pca\", pca),\n",
    "    (\"classifier\", model)\n",
    "]\n",
    "\n",
    "ipipeline_s_f = ImbPipeline(steps=steps)\n",
    "\n",
    "print(\"Model: \")\n",
    "compute_acc_rec_prec_f1_with_cv(model, X, y, cv_n=10)\n",
    "print(\"Model with PCA:\")\n",
    "compute_acc_rec_prec_f1_with_cv(pipeline, X, y, cv_n=10)\n",
    "print(\"Model with PCA and undersampling:\")\n",
    "compute_acc_rec_prec_f1_with_cv(ipipeline, X, y, cv_n=10)\n",
    "print(\"Model with PCA and scaling:\")\n",
    "compute_acc_rec_prec_f1_with_cv(pipeline_s, X, y, cv_n=10)\n",
    "print(\"Model with PCA, scaling and undersampling:\")\n",
    "compute_acc_rec_prec_f1_with_cv(ipipeline_s, X, y, cv_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84968c74d424961bfafa959b63935ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report report.html was generated.\n"
     ]
    }
   ],
   "source": [
    "report = sv.analyze(df)\n",
    "report.show_html(\"reports/report.html\", open_browser=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
