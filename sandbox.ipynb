{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "- No missing values (good)\n",
    "- There are features with slight colleration w.r.t. the Attrition (they are also explainable)\n",
    "- There are three features immediately to be dropped because of 1 distinct value\n",
    "- We are left with 19 categorical and 13 numerical features\n",
    "- ID type of feature is also excluded (numerical features down to 12)\n",
    "- Number of numerical features gone up to 23, nominals down to 7, because of instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.tree import ExtraTreeClassifier as ETC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression as LRC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "from utils.evaluation import *\n",
    "from utils.dataprep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \n",
      "Model with PCA:\n",
      "Model with PCA and undersampling:\n",
      "Model with PCA and scaling:\n",
      "Accuracy score: 88.50340136054422 +/- 1.8367346938775533\n",
      "Recall score: 38.858695652173914 +/- 9.242770666787301\n",
      "Precision score: 79.91816516816516 +/- 11.228336441424013\n",
      "F1 score: 51.6780697909106 +/- 9.382382472009791\n",
      "Model with PCA, scaling and undersampling:\n",
      "Accuracy score: 73.87755102040816 +/- 2.5850340136054415\n",
      "Recall score: 74.69202898550724 +/- 4.907414425245215\n",
      "Precision score: 35.535737534104754 +/- 2.855893696338728\n",
      "F1 score: 48.04205272840555 +/- 2.7668686004296434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 73.87755102040816,\n",
       "  'recall': 74.69202898550724,\n",
       "  'precision': 35.535737534104754,\n",
       "  'f1': 48.04205272840555},\n",
       " {'accuracy': 2.5850340136054415,\n",
       "  'recall': 4.907414425245215,\n",
       "  'precision': 2.855893696338728,\n",
       "  'f1': 2.7668686004296434})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/use_case_employee-attrition.csv\")\n",
    "df = df.drop([\"EmployeeCount\", \"Over18\", \"StandardHours\", \"EmployeeNumber\"], axis=1)\n",
    "\n",
    "nominals = [\"BusinessTravel\", \"Department\", \"EducationField\", \"Gender\", \"JobRole\", \"MaritalStatus\", \"OverTime\"]\n",
    "numericals = [\"Age\", \"DailyRate\", \"DistanceFromHome\", \"Education\", \"EnvironmentSatisfaction\", \"HourlyRate\", \"JobInvolvement\", \"JobLevel\", \"JobSatisfaction\", \"MonthlyIncome\", \"MonthlyRate\", \"NumCompaniesWorked\",\n",
    "              \"PercentSalaryHike\", \"PerformanceRating\", \"RelationshipSatisfaction\", \"StockOptionLevel\", \"TotalWorkingYears\", \"TrainingTimesLastYear\", \"WorkLifeBalance\", \"YearsAtCompany\", \"YearsInCurrentRole\", \n",
    "              \"YearsSinceLastPromotion\", \"YearsWithCurrManager\"]\n",
    "\n",
    "df_t = onehot_columns(df, nominals)\n",
    "df_n = merge_onehotted(df, df_t, nominals)\n",
    "\n",
    "X = df_n.drop(\"Attrition\", axis=1)\n",
    "y = df_n[\"Attrition\"]\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "pca = PCA(n_components=15)\n",
    "resampler = RandomUnderSampler(random_state=42)\n",
    "model = LRC(random_state=42, penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.5)\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"pca\", pca, df_t.columns),\n",
    "        (\"passthrough\", \"passthrough\", numericals)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"column_transformer\", column_transformer), (\"classifier\", model)])\n",
    "pipeline_s = Pipeline(steps=[(\"column_transformer\", column_transformer), (\"scaler\", scaler), (\"classifier\", model)])\n",
    "\n",
    "steps = [\n",
    "    (\"undersample\", resampler),\n",
    "    (\"pca\", pca),\n",
    "    (\"classifier\", model)\n",
    "]\n",
    "\n",
    "ipipeline = ImbPipeline(steps=steps)\n",
    "\n",
    "steps = [\n",
    "    (\"undersample\", resampler),\n",
    "    (\"scaler\", scaler),\n",
    "    (\"pca\", pca),\n",
    "    (\"classifier\", model)\n",
    "]\n",
    "\n",
    "ipipeline_s = ImbPipeline(steps=steps)\n",
    "\n",
    "steps = [\n",
    "    (\"undersample\", resampler),\n",
    "    (\"scaler\", scaler),\n",
    "    (\"pca\", pca),\n",
    "    (\"classifier\", model)\n",
    "]\n",
    "\n",
    "ipipeline_s_f = ImbPipeline(steps=steps)\n",
    "\n",
    "print(\"Model: \")\n",
    "#compute_acc_rec_prec_f1_with_cv(model, X, y, cv_n=10)\n",
    "print(\"Model with PCA:\")\n",
    "#compute_acc_rec_prec_f1_with_cv(pipeline, X, y, cv_n=10)\n",
    "print(\"Model with PCA and undersampling:\")\n",
    "#compute_acc_rec_prec_f1_with_cv(ipipeline, X, y, cv_n=10)\n",
    "print(\"Model with PCA and scaling:\")\n",
    "compute_acc_rec_prec_f1_with_cv(pipeline_s, X, y, cv_n=10)\n",
    "print(\"Model with PCA, scaling and undersampling:\")\n",
    "compute_acc_rec_prec_f1_with_cv(ipipeline_s, X, y, cv_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84968c74d424961bfafa959b63935ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report report.html was generated.\n"
     ]
    }
   ],
   "source": [
    "report = sv.analyze(df)\n",
    "report.show_html(\"report.html\", open_browser=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
